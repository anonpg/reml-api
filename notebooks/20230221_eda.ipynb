{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92d0526-4179-43de-a7a6-011e7b27b12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, QuantileTransformer\n",
    "from sklearn.ensemble import BaggingRegressor, StackingRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.feature_selection import RFE\n",
    "import lzma\n",
    "import cloudpickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "291ae7d9-be07-4cb0-9586-90b29be7606e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "宅地(土地と建物)    1773082\n",
      "宅地(土地)       1695314\n",
      "中古マンション等      784713\n",
      "農地            418774\n",
      "林地            208322\n",
      "Name: type, dtype: int64\n",
      "木造                 1305873\n",
      "ＲＣ                  607919\n",
      "ＳＲＣ                 233460\n",
      "鉄骨造                 151263\n",
      "軽量鉄骨造                90141\n",
      "ＲＣ、木造                 5734\n",
      "ブロック造                 4096\n",
      "鉄骨造、木造                3305\n",
      "ＳＲＣ、ＲＣ                 912\n",
      "ＲＣ、鉄骨造                 805\n",
      "木造、軽量鉄骨造               754\n",
      "ＲＣ、ブロック造               440\n",
      "木造、ブロック造               394\n",
      "ＳＲＣ、鉄骨造                217\n",
      "鉄骨造、ブロック造              192\n",
      "鉄骨造、軽量鉄骨造              132\n",
      "ＲＣ、軽量鉄骨造                78\n",
      "ＲＣ、鉄骨造、木造               41\n",
      "ＳＲＣ、木造                  38\n",
      "鉄骨造、木造、ブロック造            37\n",
      "鉄骨造、木造、軽量鉄骨造            33\n",
      "ＲＣ、木造、ブロック造             32\n",
      "ブロック造、軽量鉄骨造             23\n",
      "ＲＣ、木造、軽量鉄骨造             17\n",
      "木造、ブロック造、軽量鉄骨造          10\n",
      "ＳＲＣ、ブロック造                7\n",
      "ＲＣ、鉄骨造、軽量鉄骨造             7\n",
      "ＲＣ、鉄骨造、ブロック造             5\n",
      "鉄骨造、ブロック造、軽量鉄骨造          4\n",
      "ＲＣ、ブロック造、軽量鉄骨造           4\n",
      "ＳＲＣ、ＲＣ、鉄骨造               3\n",
      "ＲＣ、鉄骨造、木造、ブロック造          1\n",
      "ＳＲＣ、木造、ブロック造             1\n",
      "ＳＲＣ、軽量鉄骨造                1\n",
      "鉄骨造、ＲＣ、木造                1\n",
      "Name: structure, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_code</th>\n",
       "      <th>nearest_sta_dist</th>\n",
       "      <th>price</th>\n",
       "      <th>tubo_price</th>\n",
       "      <th>area</th>\n",
       "      <th>m2_price</th>\n",
       "      <th>frontage</th>\n",
       "      <th>floor_area</th>\n",
       "      <th>building_year</th>\n",
       "      <th>front_road_width</th>\n",
       "      <th>building_cov</th>\n",
       "      <th>floor_cov</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.474225e+06</td>\n",
       "      <td>1.787751e+06</td>\n",
       "      <td>2.474225e+06</td>\n",
       "      <td>1.695314e+06</td>\n",
       "      <td>2.474225e+06</td>\n",
       "      <td>1.695314e+06</td>\n",
       "      <td>1.631147e+06</td>\n",
       "      <td>47001.000000</td>\n",
       "      <td>51855.000000</td>\n",
       "      <td>1.721455e+06</td>\n",
       "      <td>1.682230e+06</td>\n",
       "      <td>1.682230e+06</td>\n",
       "      <td>2.474225e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.138614e+04</td>\n",
       "      <td>3.147618e+01</td>\n",
       "      <td>2.050007e+07</td>\n",
       "      <td>2.830348e+05</td>\n",
       "      <td>7.383158e+02</td>\n",
       "      <td>8.564063e+04</td>\n",
       "      <td>1.647594e+01</td>\n",
       "      <td>164.450756</td>\n",
       "      <td>1996.765847</td>\n",
       "      <td>6.946809e+00</td>\n",
       "      <td>6.008872e+01</td>\n",
       "      <td>1.910167e+02</td>\n",
       "      <td>2.014989e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.331480e+04</td>\n",
       "      <td>2.935010e+01</td>\n",
       "      <td>1.227004e+08</td>\n",
       "      <td>5.677828e+05</td>\n",
       "      <td>1.106982e+03</td>\n",
       "      <td>1.718930e+05</td>\n",
       "      <td>1.080000e+01</td>\n",
       "      <td>231.000426</td>\n",
       "      <td>18.855366</td>\n",
       "      <td>4.805502e+00</td>\n",
       "      <td>8.961918e+00</td>\n",
       "      <td>7.769822e+01</td>\n",
       "      <td>4.473016e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.101000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>2.005750e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.120800e+04</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>1.700000e+06</td>\n",
       "      <td>5.200000e+04</td>\n",
       "      <td>1.650000e+02</td>\n",
       "      <td>1.600000e+04</td>\n",
       "      <td>9.800000e+00</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>1982.000000</td>\n",
       "      <td>4.100000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>2.000000e+02</td>\n",
       "      <td>2.011250e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.120100e+04</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>7.300000e+06</td>\n",
       "      <td>1.300000e+05</td>\n",
       "      <td>2.800000e+02</td>\n",
       "      <td>3.900000e+04</td>\n",
       "      <td>1.350000e+01</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>2.000000e+02</td>\n",
       "      <td>2.015000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.220200e+04</td>\n",
       "      <td>4.500000e+01</td>\n",
       "      <td>1.800000e+07</td>\n",
       "      <td>3.000000e+05</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>9.100000e+04</td>\n",
       "      <td>1.950000e+01</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>7.600000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>2.000000e+02</td>\n",
       "      <td>2.018750e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.738200e+04</td>\n",
       "      <td>1.200000e+02</td>\n",
       "      <td>4.800000e+10</td>\n",
       "      <td>6.600000e+07</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>2.000000e+07</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2023.000000</td>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>8.000000e+01</td>\n",
       "      <td>1.300000e+03</td>\n",
       "      <td>2.022750e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          city_code  nearest_sta_dist         price    tubo_price  \\\n",
       "count  2.474225e+06      1.787751e+06  2.474225e+06  1.695314e+06   \n",
       "mean   2.138614e+04      3.147618e+01  2.050007e+07  2.830348e+05   \n",
       "std    1.331480e+04      2.935010e+01  1.227004e+08  5.677828e+05   \n",
       "min    1.101000e+03      0.000000e+00  1.000000e+02  2.000000e+00   \n",
       "25%    1.120800e+04      1.100000e+01  1.700000e+06  5.200000e+04   \n",
       "50%    2.120100e+04      2.000000e+01  7.300000e+06  1.300000e+05   \n",
       "75%    3.220200e+04      4.500000e+01  1.800000e+07  3.000000e+05   \n",
       "max    4.738200e+04      1.200000e+02  4.800000e+10  6.600000e+07   \n",
       "\n",
       "               area      m2_price      frontage    floor_area  building_year  \\\n",
       "count  2.474225e+06  1.695314e+06  1.631147e+06  47001.000000   51855.000000   \n",
       "mean   7.383158e+02  8.564063e+04  1.647594e+01    164.450756    1996.765847   \n",
       "std    1.106982e+03  1.718930e+05  1.080000e+01    231.000426      18.855366   \n",
       "min    1.000000e+01  1.000000e+00  1.000000e-01      5.000000    1945.000000   \n",
       "25%    1.650000e+02  1.600000e+04  9.800000e+00     95.000000    1982.000000   \n",
       "50%    2.800000e+02  3.900000e+04  1.350000e+01    110.000000    1997.000000   \n",
       "75%    7.500000e+02  9.100000e+04  1.950000e+01    135.000000    2015.000000   \n",
       "max    5.000000e+03  2.000000e+07  5.000000e+01   2000.000000    2023.000000   \n",
       "\n",
       "       front_road_width  building_cov     floor_cov          time  \n",
       "count      1.721455e+06  1.682230e+06  1.682230e+06  2.474225e+06  \n",
       "mean       6.946809e+00  6.008872e+01  1.910167e+02  2.014989e+05  \n",
       "std        4.805502e+00  8.961918e+00  7.769822e+01  4.473016e+02  \n",
       "min        1.000000e+00  3.000000e+01  5.000000e+01  2.005750e+05  \n",
       "25%        4.100000e+00  6.000000e+01  2.000000e+02  2.011250e+05  \n",
       "50%        6.000000e+00  6.000000e+01  2.000000e+02  2.015000e+05  \n",
       "75%        7.600000e+00  6.000000e+01  2.000000e+02  2.018750e+05  \n",
       "max        9.900000e+01  8.000000e+01  1.300000e+03  2.022750e+05  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_code</th>\n",
       "      <th>nearest_sta_dist</th>\n",
       "      <th>price</th>\n",
       "      <th>tubo_price</th>\n",
       "      <th>area</th>\n",
       "      <th>m2_price</th>\n",
       "      <th>frontage</th>\n",
       "      <th>floor_area</th>\n",
       "      <th>building_year</th>\n",
       "      <th>front_road_width</th>\n",
       "      <th>building_cov</th>\n",
       "      <th>floor_cov</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.405980e+06</td>\n",
       "      <td>2.359994e+06</td>\n",
       "      <td>2.405980e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.405980e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.523941e+06</td>\n",
       "      <td>1.618403e+06</td>\n",
       "      <td>2.315514e+06</td>\n",
       "      <td>1.622023e+06</td>\n",
       "      <td>2.308292e+06</td>\n",
       "      <td>2.308292e+06</td>\n",
       "      <td>2.405980e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.960047e+04</td>\n",
       "      <td>2.207230e+01</td>\n",
       "      <td>3.535199e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.971787e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.266616e+01</td>\n",
       "      <td>1.733695e+02</td>\n",
       "      <td>1.996314e+03</td>\n",
       "      <td>6.628892e+00</td>\n",
       "      <td>6.180047e+01</td>\n",
       "      <td>2.231854e+02</td>\n",
       "      <td>2.015079e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.087761e+04</td>\n",
       "      <td>2.364924e+01</td>\n",
       "      <td>1.936874e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.796084e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.213368e+00</td>\n",
       "      <td>2.518950e+02</td>\n",
       "      <td>1.580960e+01</td>\n",
       "      <td>4.579941e+00</td>\n",
       "      <td>1.067083e+01</td>\n",
       "      <td>1.236057e+02</td>\n",
       "      <td>4.556193e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.101000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000e-01</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.945000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>2.005750e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.223600e+04</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.600000e+00</td>\n",
       "      <td>9.500000e+01</td>\n",
       "      <td>1.985000e+03</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>2.000000e+02</td>\n",
       "      <td>2.011250e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.420500e+04</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>2.200000e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.150000e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>1.050000e+02</td>\n",
       "      <td>1.997000e+03</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>2.000000e+02</td>\n",
       "      <td>2.015250e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.720500e+04</td>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>3.500000e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>1.350000e+02</td>\n",
       "      <td>2.010000e+03</td>\n",
       "      <td>6.700000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>2.000000e+02</td>\n",
       "      <td>2.019000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.738200e+04</td>\n",
       "      <td>1.200000e+02</td>\n",
       "      <td>1.700000e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>2.023000e+03</td>\n",
       "      <td>9.990000e+01</td>\n",
       "      <td>8.000000e+01</td>\n",
       "      <td>1.300000e+03</td>\n",
       "      <td>2.022750e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          city_code  nearest_sta_dist         price  tubo_price          area  \\\n",
       "count  2.405980e+06      2.359994e+06  2.405980e+06         0.0  2.405980e+06   \n",
       "mean   1.960047e+04      2.207230e+01  3.535199e+07         NaN  1.971787e+02   \n",
       "std    1.087761e+04      2.364924e+01  1.936874e+08         NaN  2.796084e+02   \n",
       "min    1.101000e+03      0.000000e+00  1.000000e+02         NaN  1.000000e+01   \n",
       "25%    1.223600e+04      8.000000e+00  1.100000e+07         NaN  7.000000e+01   \n",
       "50%    1.420500e+04      1.400000e+01  2.200000e+07         NaN  1.150000e+02   \n",
       "75%    2.720500e+04      2.500000e+01  3.500000e+07         NaN  2.000000e+02   \n",
       "max    4.738200e+04      1.200000e+02  1.700000e+11         NaN  2.000000e+03   \n",
       "\n",
       "       m2_price      frontage    floor_area  building_year  front_road_width  \\\n",
       "count       0.0  1.523941e+06  1.618403e+06   2.315514e+06      1.622023e+06   \n",
       "mean        NaN  1.266616e+01  1.733695e+02   1.996314e+03      6.628892e+00   \n",
       "std         NaN  8.213368e+00  2.518950e+02   1.580960e+01      4.579941e+00   \n",
       "min         NaN  4.000000e-01  5.000000e+00   1.945000e+03      1.000000e+00   \n",
       "25%         NaN  7.600000e+00  9.500000e+01   1.985000e+03      4.000000e+00   \n",
       "50%         NaN  1.100000e+01  1.050000e+02   1.997000e+03      6.000000e+00   \n",
       "75%         NaN  1.500000e+01  1.350000e+02   2.010000e+03      6.700000e+00   \n",
       "max         NaN  5.000000e+01  2.000000e+03   2.023000e+03      9.990000e+01   \n",
       "\n",
       "       building_cov     floor_cov          time  \n",
       "count  2.308292e+06  2.308292e+06  2.405980e+06  \n",
       "mean   6.180047e+01  2.231854e+02  2.015079e+05  \n",
       "std    1.067083e+01  1.236057e+02  4.556193e+02  \n",
       "min    3.000000e+01  5.000000e+01  2.005750e+05  \n",
       "25%    6.000000e+01  2.000000e+02  2.011250e+05  \n",
       "50%    6.000000e+01  2.000000e+02  2.015250e+05  \n",
       "75%    6.000000e+01  2.000000e+02  2.019000e+05  \n",
       "max    8.000000e+01  1.300000e+03  2.022750e+05  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.506992021851541\n",
      "2474225\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle('/tmp/all.pkl')\n",
    "\n",
    "# display(df.loc[df['city2'].isnull()])\n",
    "# print(df.isnull().sum())\n",
    "print(df['type'].value_counts())\n",
    "print(df['structure'].value_counts())\n",
    "\n",
    "display(df.loc[df['structure'].isnull()].describe())\n",
    "display(df.loc[~df['structure'].isnull()].describe())\n",
    "print(df['structure'].isnull().mean())\n",
    "print(df['structure'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07a94d3b-6547-44c2-b06b-9324a3e7e16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# available features\n",
    "features = [\n",
    "    'type',\n",
    "    # 'zone_type',\n",
    "    'city_plan',\n",
    "    'city_code',\n",
    "    'prefecture',\n",
    "    'city',\n",
    "    'city2',\n",
    "    'nearest_sta',\n",
    "    'nearest_sta_dist',\n",
    "    'age',\n",
    "    # 'structure',\n",
    "    'area',\n",
    "    'floor_area',\n",
    "    # 'layout', # many nan\n",
    "    # 'front_road_dir',\n",
    "    # 'front_road_type',\n",
    "    'front_road_width',\n",
    "    # 'building_cov',\n",
    "    # 'floor_cov',\n",
    "    'building_year',\n",
    "    'time',\n",
    "    # 'choume'\n",
    "    # 'sawa',\n",
    "    # 'numa',\n",
    "    # 'tani',\n",
    "    # 'ken',\n",
    "    'city_code_low',\n",
    "    # 'city_code_low2',\n",
    "    # 'city2_last',\n",
    "    # 'city2_first',\n",
    "    # 'city_last',\n",
    "    # 'city_first',\n",
    "    # 'city2_len',\n",
    "    # 'city_len',\n",
    "    # 'floor_area_area',\n",
    "    # 'area_front_road_width',\n",
    "    # 'area_front_road_width2',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8d16ae4-6a40-44a2-958d-41b37ca7dd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_importance(model, features):\n",
    "    importances = model.feature_importances_\n",
    "    feature_imp = pd.DataFrame(zip(importances, features), columns=['value', 'feature'])\n",
    "    feature_imp = feature_imp.sort_values('value')\n",
    "    display(feature_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57c51e72-c79a-46e7-aea3-a076db14c569",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemlModel:\n",
    "    def __init__(self, df_all):\n",
    "        self._city_code_map = df_all.groupby(['prefecture', 'city'])[['city_code']].nth(0)\n",
    "        self._dtypes = df_all.dtypes\n",
    "\n",
    "    def fit(self, df, mean_only=False):\n",
    "        df = df.copy()\n",
    "        \n",
    "        cat_features = [\n",
    "            'type',\n",
    "            'city_plan',\n",
    "            'prefecture',\n",
    "            'city',\n",
    "            'city2',\n",
    "            'nearest_sta',\n",
    "            # 'structure',\n",
    "            # 'layout',\n",
    "            # 'front_road_dir',\n",
    "            # 'front_road_type',\n",
    "            # 'city2_last',\n",
    "            # 'city2_first',\n",
    "            # 'city_last',\n",
    "            # 'city_first',\n",
    "        ]\n",
    "        num_features = [x for x in features if x not in cat_features]\n",
    "        # num_features = [features.index(x) for x in num_features]\n",
    "        # cat_features = [features.index(x) for x in cat_features]\n",
    "        \n",
    "        def create_model(alpha=None):\n",
    "            n_est_scale = 10\n",
    "            \n",
    "            model = lgb.LGBMRegressor(\n",
    "                alpha=alpha,\n",
    "                objective='regression' if alpha is None else 'quantile',\n",
    "                n_estimators=100 * n_est_scale,\n",
    "                learning_rate=0.1 / n_est_scale,\n",
    "                # colsample_bytree=0.5,\n",
    "                subsample=0.5,\n",
    "                subsample_freq=1,\n",
    "                # extra_trees=True,\n",
    "                importance_type='gain',\n",
    "                random_state=1, \n",
    "                n_jobs=-1\n",
    "            )\n",
    "            et = lgb.LGBMRegressor(\n",
    "                n_estimators=100 * n_est_scale,\n",
    "                learning_rate=0.1 / n_est_scale,\n",
    "                colsample_bytree=0.5,\n",
    "                subsample=0.5,\n",
    "                subsample_freq=1,\n",
    "                extra_trees=True,\n",
    "                random_state=1, \n",
    "                n_jobs=-1\n",
    "            )\n",
    "            rf = lgb.LGBMRegressor(\n",
    "                n_estimators=100 * n_est_scale,\n",
    "                learning_rate=0.1 / n_est_scale,\n",
    "                boosting_type='rf',\n",
    "                colsample_bytree=0.5,\n",
    "                subsample=0.5,\n",
    "                subsample_freq=1,\n",
    "                # extra_trees=True,\n",
    "                random_state=1, \n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            xg = xgb.XGBRegressor(\n",
    "                random_state=1,\n",
    "                n_jobs=-1,\n",
    "            )\n",
    "            cb = CatBoostRegressor(\n",
    "                verbose=0,\n",
    "                random_state=1,\n",
    "                thread_count=-1,\n",
    "            )\n",
    "            \n",
    "            num_transformer = Pipeline([\n",
    "                (\"imputer\", SimpleImputer(strategy=\"median\")), \n",
    "                # (\"scaler\", StandardScaler()),\n",
    "                (\"qt\", QuantileTransformer(output_distribution='normal', random_state=1)),\n",
    "                (\"fe\", FeatureUnion([\n",
    "                    ('pt', 'passthrough'),\n",
    "                    ('pca', PCA(n_components=2)),\n",
    "                ])),\n",
    "            ])\n",
    "\n",
    "            cat_transformer = Pipeline([\n",
    "                (\"le\", OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1, encoded_missing_value=np.nan)),\n",
    "            ])\n",
    "            \n",
    "            ridge = Pipeline([\n",
    "                ('ct', ColumnTransformer([\n",
    "                    (\"num\", num_transformer, np.arange(len(num_features))),\n",
    "                ])),\n",
    "                ('model', RidgeCV()),\n",
    "            ])\n",
    "            \n",
    "            # model = RFE(model)\n",
    "            # model = BaggingRegressor(model, n_estimators=10, random_state=1)\n",
    "            # model = StackingRegressor([('m', model)], final_estimator=model, cv=None, n_jobs=None, passthrough=True, verbose=0) # good\n",
    "            model = StackingRegressor([\n",
    "                ('m', model),\n",
    "                ('qt_m', TransformedTargetRegressor(model, transformer=QuantileTransformer(output_distribution='normal', random_state=1))),\n",
    "                ('et', et),\n",
    "                ('rf', rf),\n",
    "                ('xg', xg), # good\n",
    "                ('cb', cb), # good\n",
    "                ('ridge', ridge),\n",
    "            ], final_estimator=model, cv=None, n_jobs=None, passthrough=True, verbose=0) # good\n",
    "\n",
    "            model = Pipeline([\n",
    "                ('ct', ColumnTransformer([\n",
    "                    (\"num\", 'passthrough', num_features),\n",
    "                    # (\"num\", num_transformer, num_features),\n",
    "                    (\"cat\", cat_transformer, cat_features),\n",
    "                ])),\n",
    "                ('model', model),\n",
    "            ])\n",
    "\n",
    "            # model = BaggingRegressor(model, n_estimators=10, random_state=1)\n",
    "            \n",
    "            return model\n",
    "        \n",
    "        df = df.sample(frac=1, random_state=1) # for ordinal encoder\n",
    "        \n",
    "        # y = np.log(df['price'])\n",
    "        y = np.log(df['price'] / df['area'])\n",
    "        # plt.hist(y, bins=100)\n",
    "        # plt.show()\n",
    "        X = self.calc_features(df)\n",
    "        \n",
    "        model = create_model()\n",
    "        model.fit(X, y)\n",
    "        \n",
    "        # show_importance(model.named_steps['model'], num_features + cat_features)\n",
    "        # show_importance(model.named_steps['model'].estimators_[0], num_features + cat_features)\n",
    "        \n",
    "        self._model = model\n",
    "        \n",
    "        self.mean_only = mean_only\n",
    "        if not mean_only:\n",
    "            model = create_model(alpha=0.1)\n",
    "            model.fit(X, y)\n",
    "            self._model_10 = model\n",
    "            model = create_model(alpha=0.9)\n",
    "            model.fit(X, y)\n",
    "            self._model_90 = model\n",
    "    \n",
    "    def predict(self, df):\n",
    "        df = df.copy()\n",
    "        \n",
    "        for col in df.columns:\n",
    "            if col in self._dtypes:\n",
    "                df[col] = df[col].astype(self._dtypes[col])\n",
    "        \n",
    "        X = self.calc_features(df)\n",
    "        # return np.exp(self._model.predict(X))\n",
    "        \n",
    "        df_res = pd.DataFrame(index=df.index)\n",
    "        df_res['price'] = np.exp(self._model.predict(X)) * df['area'].values\n",
    "        if not self.mean_only:\n",
    "            df_res['price_10'] = np.exp(self._model_10.predict(X)) * df['area'].values\n",
    "            df_res['price_90'] = np.exp(self._model_90.predict(X)) * df['area'].values\n",
    "        # df_res['price'] = np.exp(self._model.predict(X))\n",
    "        # df_res['price_10'] = np.exp(self._model_10.predict(X))\n",
    "        # df_res['price_90'] = np.exp(self._model_90.predict(X))\n",
    "        \n",
    "        return df_res\n",
    "    \n",
    "    def metadata(self):\n",
    "        return {\n",
    "            'unique_values': self._unique_values,\n",
    "        }\n",
    "    \n",
    "    def calc_features(self, df):\n",
    "        df_orig = df.reset_index()\n",
    "        df = df_orig.copy()\n",
    "        \n",
    "        df = df.merge(self._city_code_map, how='inner', on=['prefecture', 'city'])\n",
    "        df = df.set_index('index').loc[df_orig['index']]\n",
    "        \n",
    "#         from kanjize import kanji2number\n",
    "#         def conv_kanji(x):\n",
    "#             if isinstance(x, float):\n",
    "#                 return 0\n",
    "#             print(x)\n",
    "#             return kanji2number(x)\n",
    "        \n",
    "#         df['choume'] = df['city2'].str.extract(r'([一二三四五六七八九十]+)丁目')\n",
    "#         df['choume'] = df['choume'].apply(conv_kanji).astype('int')\n",
    "        \n",
    "        # df['sawa'] = df['city2'].str.contains('沢')\n",
    "        # df['numa'] = df['city2'].str.contains('沼')\n",
    "        # df['tani'] = df['city2'].str.contains('谷')\n",
    "\n",
    "        # df['ken'] = df['prefecture'].str.contains('県')\n",
    "        df['city_code_low'] = df['city_code'] % 1000\n",
    "        # df['city_code_low2'] = df['city_code'] % 100\n",
    "    \n",
    "        df['age'] = df['time'] - df['building_year'] * 100\n",
    "        \n",
    "        df['city2_last'] = df['city2'].str[-1:]\n",
    "        df['city2_first'] = df['city2'].str[:1]\n",
    "        df['city_last'] = df['city'].str[-1:]\n",
    "        df['city_first'] = df['city'].str[:1]\n",
    "        df['city2_len'] = df['city2'].str.len()\n",
    "        df['city_len'] = df['city'].str.len()\n",
    "        \n",
    "        df['floor_area_area'] = df['floor_area'] / df['area']\n",
    "        df['area_front_road_width'] = df['area'] / df['front_road_width']\n",
    "        df['area_front_road_width2'] = df['area'] / df['front_road_width'] ** 2\n",
    "\n",
    "        # display(df)\n",
    "        # display(df_orig)\n",
    "        \n",
    "        df = df[features]\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52395338-b56c-49f8-8cde-8d7077de6dcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# df = df.iloc[::100]\u001b[39;00m\n\u001b[1;32m     13\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcity_code\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# print(model.metadata())\u001b[39;00m\n\u001b[1;32m     18\u001b[0m data \u001b[38;5;241m=\u001b[39m cloudpickle\u001b[38;5;241m.\u001b[39mdumps(model)\n",
      "Cell \u001b[0;32mIn [5], line 143\u001b[0m, in \u001b[0;36mRemlModel.fit\u001b[0;34m(self, df, mean_only)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mean_only:\n\u001b[1;32m    142\u001b[0m     model \u001b[38;5;241m=\u001b[39m create_model(alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m--> 143\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_10 \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m    145\u001b[0m     model \u001b[38;5;241m=\u001b[39m create_model(alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py:382\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    381\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 382\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_stacking.py:866\u001b[0m, in \u001b[0;36mStackingRegressor.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;124;03m\"\"\"Fit the estimators.\u001b[39;00m\n\u001b[1;32m    845\u001b[0m \n\u001b[1;32m    846\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;124;03m    Returns a fitted instance.\u001b[39;00m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    865\u001b[0m y \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 866\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_stacking.py:232\u001b[0m, in \u001b[0;36m_BaseStacking.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    227\u001b[0m         cv\u001b[38;5;241m.\u001b[39mrandom_state \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mRandomState()\n\u001b[1;32m    229\u001b[0m     fit_params \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    230\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m: sample_weight} \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     )\n\u001b[0;32m--> 232\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcross_val_predict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_estimators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack_method_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdrop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;66;03m# Only not None or not 'drop' estimators will be used in transform.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# Remove the None from the method as well.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_method_ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    250\u001b[0m     meth\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (meth, est) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_method_, all_estimators)\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m est \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m ]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:968\u001b[0m, in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    967\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 968\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_predict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    975\u001b[0m inv_test_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mlen\u001b[39m(test_indices), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    976\u001b[0m inv_test_indices[test_indices] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(test_indices))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:1050\u001b[0m, in \u001b[0;36m_fit_and_predict\u001b[0;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[1;32m   1048\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1050\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1051\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(estimator, method)\n\u001b[1;32m   1052\u001b[0m predictions \u001b[38;5;241m=\u001b[39m func(X_test)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:1025\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m (\n\u001b[1;32m   1017\u001b[0m     model,\n\u001b[1;32m   1018\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1024\u001b[0m )\n\u001b[0;32m-> 1025\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle('/tmp/all.pkl')\n",
    "# df = df.loc[df['type'] == '宅地(土地)']\n",
    "# df = df.loc[df['type'] == '宅地(土地と建物)']\n",
    "# df = df.loc[df['type'] == '中古マンション等']\n",
    "# df = df.loc[df['type'] == '農地']\n",
    "# df = df.loc[df['type'] == '林地']\n",
    "# df = df.loc[df['type'].isin(['宅地(土地と建物)', '中古マンション等'])]\n",
    "df = df.loc[df['type'].isin(['宅地(土地)', '宅地(土地と建物)', '中古マンション等'])]\n",
    "\n",
    "model = RemlModel(df)\n",
    "\n",
    "# df = df.iloc[::100]\n",
    "df = df.drop(columns='city_code')\n",
    "\n",
    "model.fit(df)\n",
    "# print(model.metadata())\n",
    "\n",
    "data = cloudpickle.dumps(model)\n",
    "data = lzma.compress(data)\n",
    "model_name = '20230221_eda'\n",
    "with open('/home/jovyan/data/{}.xz'.format(model_name), 'wb') as f:\n",
    "    f.write(data)\n",
    "print('model size {}'.format(os.path.getsize('/home/jovyan/data/{}.xz'.format(model_name))))\n",
    "\n",
    "cv = KFold(shuffle=True, random_state=1)\n",
    "\n",
    "def calc_score(y, y_pred):\n",
    "    return r2_score(np.log(y), np.log(y_pred))\n",
    "    # return pearsonr(np.log(y), np.log(y_pred))[0]\n",
    "\n",
    "scores = []\n",
    "for train_idx, val_idx in cv.split(df):\n",
    "    model.fit(df.iloc[train_idx], mean_only=True)\n",
    "    \n",
    "    df_val = df.iloc[val_idx]\n",
    "    df_res = model.predict(df_val)\n",
    "    y_pred = df_res['price']\n",
    "    y = df_val['price']\n",
    "    score = calc_score(y, y_pred)\n",
    "    scores += [{ 'score': score, 'type': 'all' }]\n",
    "    print('score {}'.format(score))\n",
    "    \n",
    "    for tp, df_type in df_val.groupby('type'):\n",
    "        score = calc_score(y.loc[df_type.index], y_pred.loc[df_type.index])\n",
    "        scores += [{ 'score': score, 'type': tp }]\n",
    "        print('{} score {}'.format(tp, score))\n",
    "\n",
    "df_score = pd.DataFrame(scores)\n",
    "display(df_score.groupby('type')[['score']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "8823c7d5-86bb-4705-a353-302b6273e679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metadata(df):\n",
    "    unique_values = {}\n",
    "    for col in df.columns:\n",
    "        unique_values[col] = df[col].sort_values().unique().tolist()\n",
    "\n",
    "    x = df['prefecture']\n",
    "    x = x + ':' + df['city']\n",
    "    x = x + ':' + df['city2']\n",
    "    x = x + ':' + df['nearest_sta']\n",
    "    unique_values['prefecture_city_city2_nearest_sta'] = x.sort_values().unique().tolist()\n",
    "    \n",
    "    return {\n",
    "        'unique_values': unique_values,\n",
    "    }\n",
    "\n",
    "df = pd.read_pickle('/tmp/all.pkl')\n",
    "df = df.loc[df['type'].isin(['宅地(土地)', '宅地(土地と建物)', '中古マンション等'])]\n",
    "metadata = create_metadata(df)\n",
    "\n",
    "data = cloudpickle.dumps(metadata)\n",
    "data = lzma.compress(data)\n",
    "with open('/home/jovyan/data/{}_metadata.xz'.format(model_name), 'wb') as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5418e71-1dba-463a-8d68-72db1fc0508c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
